{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNMKuxAo+9kkgV6vDPfncnO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadeensayed/CNN_ImageClassification/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U30sBvq9NKob",
        "outputId": "901c5d12-33d3-4af7-8901-3f941c45f070"
      },
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrVJBweTNesZ"
      },
      "source": [
        "#DATASET 1, 2 CATEGORIES\n",
        "\n",
        "# !unzip /content/drive/MyDrive/Orange.zip\n",
        "\n",
        "# Import the necessary libraries\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from os import listdir\n",
        "from matplotlib import image\n",
        "import cv2\n",
        "\n",
        "#TRAINING SET\n",
        "X_train = []\n",
        "Y_train = []\n",
        "# load all images in a G1\n",
        "for filename in listdir('/content/Orange/Training/Orange G1'):\n",
        " path='/content/Orange/Training/Orange G1/'+ filename\n",
        " im = cv2.imread(path)\n",
        " img = cv2.resize(im, (227,227), interpolation = cv2.INTER_AREA)\n",
        " p=np.array(img)\n",
        " X_train.append(p)\n",
        " Y_train.append(0)\n",
        "\n",
        "# load all images in a G2\n",
        "for filename in listdir('/content/Orange/Training/Orange G2'):\n",
        " path='/content/Orange/Training/Orange G2/'+ filename\n",
        " im = cv2.imread(path)\n",
        " img = cv2.resize(im, (227,227), interpolation = cv2.INTER_AREA)\n",
        " p=np.array(img)\n",
        " X_train.append(p)\n",
        " Y_train.append(0)\n",
        "\n",
        "# load all images in rotten\n",
        "for filename in listdir('/content/Orange/Training/Orange Rotten'):\n",
        " path='/content/Orange/Training/Orange Rotten/'+ filename\n",
        " im = cv2.imread(path)\n",
        " img = cv2.resize(im, (227,227), interpolation = cv2.INTER_AREA)\n",
        " p=np.array(img)\n",
        " X_train.append(p)\n",
        " Y_train.append(1)\n",
        "\n",
        "X_train=np.array(X_train)\n",
        "Y_train=np.array(Y_train)\n",
        "X_train =X_train / 255\n",
        "\n",
        "\n",
        "#TESTING SET\n",
        "X_test = []\n",
        "Y_test = []\n",
        "# load all images in a G1\n",
        "for filename in listdir('/content/Orange/Testing/Orange G1'):\n",
        " path='/content/Orange/Testing/Orange G1/'+ filename\n",
        " im = cv2.imread(path)\n",
        " img = cv2.resize(im, (227,227), interpolation = cv2.INTER_AREA)\n",
        " p=np.array(img)\n",
        " X_test.append(p)\n",
        " Y_test.append(0)\n",
        "\n",
        "# load all images in a G2\n",
        "for filename in listdir('/content/Orange/Testing/Orange G2'):\n",
        " path='/content/Orange/Testing/Orange G2/'+ filename\n",
        " im = cv2.imread(path)\n",
        " img = cv2.resize(im, (227,227), interpolation = cv2.INTER_AREA)\n",
        " p=np.array(img)\n",
        " X_test.append(p)\n",
        " Y_test.append(0)\n",
        "\n",
        "# load all images in rotten\n",
        "for filename in listdir('/content/Orange/Testing/Orange Rotten'):\n",
        " path='/content/Orange/Testing/Orange Rotten/'+ filename\n",
        " im = cv2.imread(path)\n",
        " img = cv2.resize(im, (227,227), interpolation = cv2.INTER_AREA)\n",
        " p=np.array(img)\n",
        " X_test.append(p)\n",
        " Y_test.append(1)\n",
        " \n",
        "X_test=np.array(X_test)\n",
        "Y_test=np.array(Y_test)\n",
        "X_test = X_test / 255\n",
        "\n",
        "#MODEL \n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D\n",
        "from keras.utils import np_utils\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "cnn = models.Sequential([\n",
        "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(227, 227, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)), \n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    # layers.Dropout(0.4),\n",
        "    layers.Dense(2, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# looking at the model summary\n",
        "cnn.summary()\n",
        "# compiling the sequential model\n",
        "cnn.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "# training the model for 10 epochs\n",
        "history= cnn.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dd_T9WocR-X"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZP_oosaO87d"
      },
      "source": [
        "#DATASET 2, 2 CATEGORIES\n",
        "\n",
        "!unzip /content/drive/MyDrive/Dataset2.zip\n",
        "\n",
        "\n",
        "# Import the necessary libraries\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from os import listdir\n",
        "from matplotlib import image\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from matplotlib import pyplot\n",
        "\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "# load all images in Fresh\n",
        "for filename in listdir('/content/Dataset/Oranges Dataset 2/'):\n",
        " path='/content/Dataset/Oranges Dataset 2/'+ filename\n",
        " im = cv2.imread(path)\n",
        " img = cv2.resize(im, (227,227), interpolation = cv2.INTER_AREA)\n",
        " p=np.array(img)\n",
        " X.append(p)\n",
        " Y.append(0)\n",
        "\n",
        "# load all images in Rotten\n",
        "for filename in listdir('/content/Dataset/Rotten Orange  Dataset/'):\n",
        " path='/content/Dataset/Rotten Orange  Dataset/'+ filename\n",
        " im = cv2.imread(path)\n",
        " img = cv2.resize(im, (227,227), interpolation = cv2.INTER_AREA)\n",
        " p=np.array(img)\n",
        " X.append(p)\n",
        " Y.append(1)\n",
        "\n",
        "X=np.array(X)\n",
        "Y=np.array(Y)\n",
        "\n",
        "\n",
        "X_Train, X_Test, Y_Train, Y_Test = train_test_split(X, Y, test_size=0.33)\n",
        "\n",
        "X_Test=np.array(X_Test)\n",
        "Y_Test=np.array(Y_Test)\n",
        "X_Train=np.array(X_Train)\n",
        "Y_Train=np.array(Y_Train)\n",
        "\n",
        "X_Test = X_Test / 255\n",
        "X_Train = X_Train / 255\n",
        "\n",
        "#MODEL \n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D\n",
        "from keras.utils import np_utils\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "cnn = models.Sequential([\n",
        "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(227, 227, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)), \n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(2, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# looking at the model summary\n",
        "cnn.summary()\n",
        "# compiling the sequential model\n",
        "cnn.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "# training the model for 10 epochs\n",
        "history= cnn.fit(X_Train, Y_Train, batch_size=128, epochs=10, validation_data=(X_Test, Y_Test))\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "UfhjK54PwHDq",
        "outputId": "04423302-4b53-463c-afd7-e50b1daf5763"
      },
      "source": [
        "print(X_train[1224],Y_train[1224])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-fce35c3b8e4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1224\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1224\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpuDogDzTqAu"
      },
      "source": [
        "#DATASET 1, 3 CATEGORIES\n",
        "\n",
        "# !unzip /content/drive/MyDrive/Orange.zip\n",
        "\n",
        "# Import the necessary libraries\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from os import listdir\n",
        "from matplotlib import image\n",
        "import cv2\n",
        "\n",
        "#TRAINING SET\n",
        "X_train = []\n",
        "Y_train = []\n",
        "# load all images in a G1\n",
        "for filename in listdir('/content/Orange/Training/Orange G1'):\n",
        " path='/content/Orange/Training/Orange G1/'+ filename\n",
        " im = cv2.imread(path)\n",
        " img = cv2.resize(im, (227,227), interpolation = cv2.INTER_AREA)\n",
        " p=np.array(img)\n",
        " X_train.append(p)\n",
        " Y_train.append(0)\n",
        "\n",
        "# load all images in a G2\n",
        "for filename in listdir('/content/Orange/Training/Orange G2'):\n",
        " path='/content/Orange/Training/Orange G2/'+ filename\n",
        " im = cv2.imread(path)\n",
        " img = cv2.resize(im, (227,227), interpolation = cv2.INTER_AREA)\n",
        " p=np.array(img)\n",
        " X_train.append(p)\n",
        " Y_train.append(1)\n",
        "\n",
        "# load all images in rotten\n",
        "for filename in listdir('/content/Orange/Training/Orange Rotten'):\n",
        " path='/content/Orange/Training/Orange Rotten/'+ filename\n",
        " im = cv2.imread(path)\n",
        " img = cv2.resize(im, (227,227), interpolation = cv2.INTER_AREA)\n",
        " p=np.array(img)\n",
        " X_train.append(p)\n",
        " Y_train.append(2)\n",
        "\n",
        "X_train=np.array(X_train)\n",
        "Y_train=np.array(Y_train)\n",
        "X_train =X_train / 255\n",
        "\n",
        "\n",
        "#TESTING SET\n",
        "X_test = []\n",
        "Y_test = []\n",
        "# load all images in a G1\n",
        "for filename in listdir('/content/Orange/Testing/Orange G1'):\n",
        " path='/content/Orange/Testing/Orange G1/'+ filename\n",
        " im = cv2.imread(path)\n",
        " img = cv2.resize(im, (227,227), interpolation = cv2.INTER_AREA)\n",
        " p=np.array(img)\n",
        " X_test.append(p)\n",
        " Y_test.append(0)\n",
        "\n",
        "# load all images in a G2\n",
        "for filename in listdir('/content/Orange/Testing/Orange G2'):\n",
        " path='/content/Orange/Testing/Orange G2/'+ filename\n",
        " im = cv2.imread(path)\n",
        " img = cv2.resize(im, (227,227), interpolation = cv2.INTER_AREA)\n",
        " p=np.array(img)\n",
        " X_test.append(p)\n",
        " Y_test.append(1)\n",
        "\n",
        "# load all images in rotten\n",
        "for filename in listdir('/content/Orange/Testing/Orange Rotten'):\n",
        " path='/content/Orange/Testing/Orange Rotten/'+ filename\n",
        " im = cv2.imread(path)\n",
        " img = cv2.resize(im, (227,227), interpolation = cv2.INTER_AREA)\n",
        " p=np.array(img)\n",
        " X_test.append(p)\n",
        " Y_test.append(2)\n",
        " \n",
        "X_test=np.array(X_test)\n",
        "Y_test=np.array(Y_test)\n",
        "X_test = X_test / 255\n",
        "\n",
        "#MODEL \n",
        "\n",
        "# from keras.datasets import mnist\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Dropout, Conv2D, MaxPool2D\n",
        "# from keras.utils import np_utils\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras import datasets, layers, models\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "\n",
        "# cnn = models.Sequential([\n",
        "#     layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(227, 227, 3)),\n",
        "#     layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "#     layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "#     layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "#     layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "#     layers.MaxPooling2D((2, 2)), \n",
        "\n",
        "#     layers.Flatten(),\n",
        "#     layers.Dense(64, activation='relu'),\n",
        "#     # layers.Dropout(0.4),\n",
        "#     layers.Dense(3, activation='softmax')\n",
        "# ])\n",
        "\n",
        "# # looking at the model summary\n",
        "# cnn.summary()\n",
        "# # compiling the sequential model\n",
        "# cnn.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "# # training the model for 10 epochs\n",
        "# cnn.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6l79L-AhXxuL",
        "outputId": "1293f33a-3922-4d68-839b-ba64cbb0f146"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D\n",
        "from keras.utils import np_utils\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "cnn = models.Sequential([\n",
        "    layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(227, 227, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    # layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
        "    # layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    # layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    # layers.MaxPooling2D((2, 2)), \n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    # layers.Dropout(0.4),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# looking at the model summary\n",
        "cnn.summary()\n",
        "# compiling the sequential model\n",
        "cnn.compile( optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# training the model for 10 epochs\n",
        "cnn.fit(X_train, Y_train,epochs=10, verbose=1,  validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 225, 225, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 112, 112, 16)      0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 200704)            0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                12845120  \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 12,845,763\n",
            "Trainable params: 12,845,763\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "49/49 [==============================] - 40s 812ms/step - loss: 1.7465 - accuracy: 0.9159 - val_loss: 0.2185 - val_accuracy: 0.9896\n",
            "Epoch 2/10\n",
            "49/49 [==============================] - 39s 803ms/step - loss: 0.2051 - accuracy: 0.9761 - val_loss: 0.0352 - val_accuracy: 0.9917\n",
            "Epoch 3/10\n",
            "49/49 [==============================] - 39s 793ms/step - loss: 0.0490 - accuracy: 0.9871 - val_loss: 0.0348 - val_accuracy: 0.9927\n",
            "Epoch 4/10\n",
            "49/49 [==============================] - 39s 793ms/step - loss: 0.0145 - accuracy: 0.9916 - val_loss: 0.0446 - val_accuracy: 0.9896\n",
            "Epoch 5/10\n",
            "49/49 [==============================] - 39s 791ms/step - loss: 0.0061 - accuracy: 0.9974 - val_loss: 0.0352 - val_accuracy: 0.9896\n",
            "Epoch 6/10\n",
            "49/49 [==============================] - 39s 792ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0428 - val_accuracy: 0.9927\n",
            "Epoch 7/10\n",
            "49/49 [==============================] - 39s 794ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0532 - val_accuracy: 0.9917\n",
            "Epoch 8/10\n",
            "49/49 [==============================] - 39s 795ms/step - loss: 2.7904e-04 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9917\n",
            "Epoch 9/10\n",
            "49/49 [==============================] - 39s 794ms/step - loss: 1.8549e-04 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9917\n",
            "Epoch 10/10\n",
            "49/49 [==============================] - 39s 797ms/step - loss: 1.5239e-04 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9917\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f783de54110>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}